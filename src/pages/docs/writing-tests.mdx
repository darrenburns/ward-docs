---
title: "Writing tests"
path: "/guide/writing-tests"
section: "user guide"
sortKey: 1
---
import {TestOutputLine, TerminalExample, XpassMarker, XfailMarker, SkipMarker, TerminalText} from "../../components/ward-test-output"
import Warning from "../../components/warning"
import {CommitExample} from  "../../components/docs-layout"

## Descriptive testing

When reading a test, it's important to understand its *purpose*.
Therefore, a test framework should make expressing that purpose in a clear and concise manner as simple as possible.

Ward lets you describe your tests using strings, allowing you to be as descriptive
as you'd like:

```python
from ward import expect, fixture, test

@test("1 + 2 equals 3")
def _():
    expect(1 + 2).equals(3)
```

The description of a test is a [format string](https://docs.python.org/3/library/string.html#format-string-syntax), and may
refer to any of the parameters (variables or fixtures) present in the test signature. This
makes it easy to keep your test data and test descriptions in sync.


```python
@fixture
def three():
    yield 3

@test("my_sum({a}, {b}) is equal to {result}")
def _(a=1, b=2, result=three):
    total = my_sum(a, b)
    expect(total).equals(result)
```

During the test run, Ward will print the descriptive test name to the console:

<TerminalExample>
    <TestOutputLine marker="FAIL" lineNumber="7" moduleName="test_my_math_module" description="my_sum(1, 2) is equal to 3" />
</TerminalExample>

## The `expect` API

Use `expect` to perform tests on objects by chaining together methods. Using `expect` allows Ward
to provide detailed, highly readable output when your tests fail.

```python
from ward import expect, fixture, test

@fixture
def cities():
    return {"edinburgh": "scotland", "tokyo": "japan", "madrid": "spain"}

@test("get_capitals_from_server should return the correct cities")
def _(cities=cities):
    found_cities = get_capitals_from_server()

    (expect(found_cities)
     .contains("tokyo")                                 # it contains the key 'tokyo'
     .satisfies(lambda x: all(len(k) < 10 for k in x))  # all keys < 10 chars
     .equals(cities))
```

Most methods on `expect` have inverted equivalents, e.g. `not_equals`, `not_satisfies`, etc.

## Parameterised testing

A parameterised test is where you define a single test that runs multiple times, 
with different arguments being injected on each run.

Ward supports parameterised testing by allowing multiple fixtures or
values to be bound as a keyword argument using the `each` function:

```python
from ward import each, fixture, test

@fixture
def six():
    return 6

@test("an example of parameterisation")
def _(
    a=each(1, 2, 3),
    b=each(2, 4, six),
):
    expect(a * 2).equals(b)
```

Although the example above is written as a single test,
Ward will generate and run 3 distinct tests from it at run-time: one for each item passed into `each`.

The variables `a` and `b` take the values `a=1` and `b=2` in the first test,
`a=2` and `b=4` in the second test, and the third test will be passed the values `a=3` and `b=6`.

If any of the items inside `each` is a fixture, that fixture will be resolved 
and injected. Each of the test runs are considered *unique tests* from 
a [fixture scoping](/guide/fixtures) perspective.

<Warning>
**Warning**: All occurrences of `each` in a test signature must contain the same number of arguments.
</Warning>
<br/>

Using `each` in a test signature doesn't stop you from injecting other fixtures as normal.

```python
from ward import each, fixture, test

@fixture
def book_api():
   return BookApi()

@test("BookApi.get_book returns the correct book given an ISBN")
def _(
   api=book_api,
   isbn=each("0765326353", "0765326361", "076532637X"),
   name=each("The Way of Kings", "Words of Radiance", "Oathbringer"),
)
   book: Book = api.get_book(isbn)
   expect(book.name).equals(name)
```

Ward will expand the parameterised test above into 3 distinct tests.

In other words, the single parameterised test above is functionally equivalent to the 3 tests shown below.

```python
@test("[1/3] BookApi.get_book returns the correct book given an ISBN")
def _(
   api=book_api,
   isbn="0765326353",
   name="The Way of Kings",
)
   book: Book = api.get_book(isbn)
   expect(book.name).equals(name)

@test("[2/3] BookApi.get_book returns the correct book given an ISBN")
def _(
   api=book_api,
   isbn="0765326361",
   name="Words of Radiance",
)
   book: Book = api.get_book(isbn)
   expect(book.name).equals(name)

@test("[3/3] BookApi.get_book returns the correct book given an ISBN")
def _(
   api=book_api,
   isbn="076532637X",
   name="Oathbringer",
)
   book: Book = api.get_book(isbn)
   expect(book.name).equals(name)
```

If you'd like to use the same `book_api` instance across each of the three generated tests, 
you'd have to increase its scope to `module` or `global`.

Currently, `each` can only be used in the signature of *tests*.

### Real-world examples

<CommitExample hash={"f85777bfaf83834381450a9ed686d777a5d05bab"} 
  url={"https://github.com/darrenburns/ward/blob/f85777bfaf83834381450a9ed686d777a5d05bab/tests/test_collect.py#L48"}
  title={"Format strings & parameterisation"} 
  repo={"darrenburns/ward"}
  description={"You can use format strings in your parameterised tests to give each run its own unique description."} />

<CommitExample hash={"f85777bfaf83834381450a9ed686d777a5d05bab"} 
  url={"https://github.com/darrenburns/ward/commit/f85777bfaf83834381450a9ed686d777a5d05bab"}
  title={"Combining tests"} 
  repo={"darrenburns/ward"}
  description={"A diff showing the refactoring of two similar tests into a single parameterised test."} />

<CommitExample hash={"7f43adcd2288fb1e8d97d3867e61fb7ef1d6ad7e"}
  url={"https://github.com/darrenburns/ward/commit/7f43adcd2288fb1e8d97d3867e61fb7ef1d6ad7e"}
  title={"Testing a mapping function with parameterise"} 
  repo={"darrenburns/ward"}
  description={"Ward maps the outcome of a test to a colour that will appear in your terminal. This test uses parameterisation to check that all of these outcomes map to the correct colour."} />


## Working with mocks

`expect` works well with `unittest.mock`, by providing methods such as `expect.called`, `expect.called_once_with`, 
and more. If a test fails due to the mock not being used as expected, Ward will print specialised output to aid
debugging the problem.

```python
from ward import test, expect
from unittest.mock import Mock

@test("the mock was called with the expected arguments")
def _():
    mock = Mock()
    mock(1, 2, x=3)
    expect(mock).called_once_with(1, 2, x=3)
```

### Real-world examples

<CommitExample hash={"8c3eaef2a7a133e1ef7d379eb5e003701e035356"}
  url={"https://github.com/darrenburns/ward/blob/8c3eaef2a7a133e1ef7d379eb5e003701e035356/tests/test_testing.py#L75"}
  title={"Ensure Test.__call__ delegates correctly"} 
  repo={"darrenburns/ward"}
  description={"Ward has an internal Test object that wraps test functions, and can be called directly. When called, \
  it should pass its arguments directly through to the test function. This test replaces the test function with a mock, \
  and ensures that the mock gets called with the same arguments as the Test object."} />

## Checking for exceptions

The test below will pass, because a `ZeroDivisionError` is raised. If a `ZeroDivisionError` wasn't raised,
the test would fail.

```python
from ward import raises, test

@test("a ZeroDivision error is raised when we divide by 0")
def _():
    with raises(ZeroDivisionError):
        1/0
```

### Real-world examples

<CommitExample hash={"f85777bfaf83834381450a9ed686d777a5d05bab"}
  url={"https://github.com/darrenburns/ward/blob/f85777bfaf83834381450a9ed686d777a5d05bab/tests/test_expect.py#L37"}
  title={"Checking an exception is raised"} 
  repo={"darrenburns/ward"}
  description={"This test checks that a call to 'expect.equals' raises an ExpectationFailed error if the arguments are not equal."} />

## Skipping a test

Use the `@skip` decorator to tell Ward not to execute a test.

```python
from ward import skip

@skip
def test_to_be_skipped():
    # ...
```

You can pass a `reason` to the `skip` decorator, and it will be printed
next to the test name/description during the run.

```python
@skip("not implemented yet")
@test("everything is okay")
def _():
    # ...
```

When we <SkipMarker>SKIP</SkipMarker> a test, like the one above, Ward will clearly highlight this
in its output:

<TerminalExample>
    <TestOutputLine marker="SKIP" moduleName="test_things" lineNumber="14" description="everything is okay" note="[not implemented yet]"/>
</TerminalExample>


## Expecting a test to fail

You can mark a test that you expect to fail with the `@xfail` decorator. 

```python
from ward import xfail

@xfail("its really not okay")
@test("everything is okay")
def _():
    # ...
```

If a test decorated with `@xfail` *does* indeed fail as we expected, it is shown
in the results as an <XfailMarker>XFAIL</XfailMarker>:

<TerminalExample>
    <TestOutputLine marker="XFAI" moduleName="test_things" lineNumber="14" description="everything is okay" note="[its really not okay]"/>
</TerminalExample>

If a test marked with this decorator passes unexpectedly, it is known as an <XpassMarker>XPASS</XpassMarker> (an unexpected pass), which will
be displayed as shown below.

<TerminalExample>
    <TestOutputLine marker="XPAS" moduleName="test_things" lineNumber="14" description="everything is okay" note="[its really not okay]"/>
</TerminalExample>

If an <XpassMarker>XPASS</XpassMarker> occurs during a run, that run will be considered a failure.

## Testing for approximate equality

Check that a value is close to another value.

```python
expect(1.0).approx(1.01, abs_tol=0.2)  # pass
expect(1.0).approx(1.01, abs_tol=0.001)  # fail
```

## Using Hypothesis with Ward

To use [Hypothesis](https://hypothesis.readthedocs.io) with Ward, you'll have to use the `@using` decorator
to inject fixtures, because Hypothesis doesn't permit the use of default arguments.